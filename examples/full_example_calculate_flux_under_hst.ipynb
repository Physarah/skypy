{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skypy.utils import package_directory, load_yaml, merge_two_dictionaries, add_to_pickel_file\n",
    "from skypy.telescopes.hst import HubbleObservation, get_hst_ceres_fluxes_hourly\n",
    "from skypy.telescopes.ceres import prep_data\n",
    "from skypy.tles import pick_the_right_tle\n",
    "\n",
    "import pandas as pd\n",
    "import os.path as path\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "### WARNING ### you must download the ceres file FIRST using the example script \"download_ceres_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where the MAST data is kept\n",
    "data_path = package_directory('data', 'MDRIZSKY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pickle path to find the stored ceres data\n",
    "pickel_path = \"/Users/physarah/Desktop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the save pickle path for each of the dictionaries created in this loop\n",
    "save_dictionaries_path = \"/Users/physarah/Desktop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where the master TLE yaml file is\n",
    "tle_dictionary = load_yaml(package_directory('data', 'tle_dictionary.yml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse MAST data into pandas dataframe\n",
    "master_data_frame = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose only exposures that are taken during the day\n",
    "data_sun_selection = master_data_frame.loc[master_data_frame['SUN_ALT'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose only GOODS fields for now\n",
    "data_goods_selection = data_sun_selection[data_sun_selection['Target Name'].str.contains(\n",
    "    \"GOODS\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose only exposures in the X bandpass (here is it F606W)\n",
    "data_final_filter_selection = data_goods_selection[data_goods_selection['FILTER1'].str.contains(\n",
    "    \"F850LP\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the data set\n",
    "data_final_selection = data_final_filter_selection\n",
    "df_to_use = data_final_selection.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the exposure to use in the list of Hubble obs\n",
    "i = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the HSTObs class for this observation\n",
    "hst_obs = HubbleObservation(df_to_use.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the expected file name for this exposure\n",
    "pickel_filename = \"FF850LP_{}\".format(hst_obs.mid_times.strftime(\"%d%m%y_%H%M%S\"))\n",
    "total_pickle_filepath = pickel_path + \"/\" + pickel_filename + \".pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved :)\n"
     ]
    }
   ],
   "source": [
    "# Check if this exists\n",
    "if not path.exists(total_pickle_filepath):\n",
    "    print(\"Skipping this one because the file doesn't exist: {}\".format(total_pickle_filepath))\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    # Open the ceres dictionary\n",
    "    try:\n",
    "        pickle_data = pickle.load(open(total_pickle_filepath, 'rb'))\n",
    "        ceres_fluxes_dict = pickle_data['sw_upward_flux'][0, :, :]\n",
    "\n",
    "        # Get the corresponding TLE\n",
    "        correct_tle = pick_the_right_tle(hst_obs.start_times, tle_dictionary)\n",
    "\n",
    "        if not correct_tle:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            # Put the data into a dataframe and add back the lon and lat\n",
    "            data_frame_organised = prep_data(ceres_fluxes_dict)\n",
    "\n",
    "            # Get the fluxes under hst\n",
    "            fluxes_in_start, fluxes_in_end, fluxes_in_mid = get_hst_ceres_fluxes_hourly(hst_obs,\n",
    "                                                                                        correct_tle,\n",
    "                                                                                        data_frame_organised)\n",
    "\n",
    "            # Compute the zodi strength\n",
    "            try:\n",
    "                hst_zodi = hst_obs.zodi_strength.value\n",
    "            except:\n",
    "                hst_zodi = -999\n",
    "\n",
    "            # Compute the average flux under hst\n",
    "            flux_start_av = np.average(fluxes_in_start)\n",
    "            flux_mid_av = np.average(fluxes_in_mid)\n",
    "            flux_end_av = np.average(fluxes_in_end)\n",
    "\n",
    "            # Compute the standard deviation in flux\n",
    "            flux_start_stdv = np.std(fluxes_in_start)\n",
    "            flux_mid_stdv = np.std(fluxes_in_mid)\n",
    "            flux_end_stdv = np.std(fluxes_in_end)\n",
    "\n",
    "            # Put it all in a dictionary\n",
    "            pickel_dict = {'f_s_av': flux_start_av,\n",
    "                           'f_m_av': flux_mid_av,\n",
    "                           'f_e_av': flux_end_av,\n",
    "                           'f_s_stdv': flux_start_stdv,\n",
    "                           'f_m_stdv': flux_mid_stdv,\n",
    "                           'f_e_stdv': flux_end_stdv,\n",
    "                           'zodi': hst_zodi}\n",
    "\n",
    "            # Put everything into the one dictionary\n",
    "            final_pickel = merge_two_dictionaries(\n",
    "                df_to_use.loc[i].to_dict(), pickel_dict)\n",
    "\n",
    "            # Save to pickle file\n",
    "            add_to_pickel_file(pickel_path=save_dictionaries_path,\n",
    "                               pickel_filename=(pickel_filename + \"arc_dict.pickle\"),\n",
    "                               pickel_dictionary=final_pickel)\n",
    "            print(\"File saved :)\")\n",
    "    except:\n",
    "        pickel_dict = {'f_s_av': -999,\n",
    "                       'f_m_av': -999,\n",
    "                       'f_e_av': -999,\n",
    "                       'f_s_stdv': -999,\n",
    "                       'f_m_stdv': -999,\n",
    "                       'f_e_stdv': -999,\n",
    "                       'zodi': -999}\n",
    "        # Put everything into the one dictionary\n",
    "        final_pickel = merge_two_dictionaries(\n",
    "            df_to_use.loc[i].to_dict(), pickel_dict)\n",
    "\n",
    "        # Save to pickle file\n",
    "        add_to_pickel_file(pickel_path=save_dictionaries_path,\n",
    "                           pickel_filename=(pickel_filename + \"arc_dict.pickle\"),\n",
    "                           pickel_dictionary=final_pickel)\n",
    "        print(\"File saved :) - With exceptions :( \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f_s_av': 285.86545,\n",
       " 'f_m_av': 274.2673,\n",
       " 'f_e_av': 246.52644,\n",
       " 'f_s_stdv': 196.01395,\n",
       " 'f_m_stdv': 192.15654,\n",
       " 'f_e_stdv': 179.38641,\n",
       " 'zodi': 1.5130043116912668e-18}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
